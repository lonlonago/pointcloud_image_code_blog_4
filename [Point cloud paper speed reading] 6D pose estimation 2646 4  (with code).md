Point cloud PCL free knowledge planet, point cloud paper speed reading. 

 标题：MoreFusion: Multi-object Reasoning for 6D Pose Estimation from Volumetric Fusion 

 作者：Kentaro Wada, Edgar Sucar, Stephen James 

 Planet ID: wl_ Huake _ point cloud processing _ target recognition 

 Welcome to join the free knowledge planet, get PDF papers, and welcome to forward Moments to share your happiness. 

 Abstracts of papers 

 Robots and other intelligent devices need to achieve efficient target-level scene representation for contact, physical, occlusion, and other inferences based on their own vision systems. Known accurate target models play a very important role in the non-parametric reconstruction of unknown structures. We propose a system that can estimate the precise pose of contacting and occluding known targets in real-time multi-view scenes. Our method can estimate the pose of 3D targets from a single RGBD perspective. As the camera moves, it can accumulate pose estimation and non-parametric occupancy information from multiple perspectives, and perform joint optimization to perform consistent non-intersecting pose estimation for multiple contact targets. 

 We experimentally validate the accuracy and robustness of our proposed method in two datasets, YCB-Video and Cluttered YCB-Video. We demonstrate an implemented robotic application that is able to precisely and orderly grasp complex stacked objects using only the RGB-D information it carries. 

 https://github.com/j96w/DenseFusion 

 ![avatar]( 20200524215334569.JPG) 

 Paper Atlas      

 ● English abstract 

 ![avatar]( 2020052421541787.JPG) 

 Robots and other smart devices need efficient objectbased scene representations from their on-board vision systems to reason about contact, physics and occlusion. Recognized precise object models will play an important role alongside non-parametric reconstructions of unrecognized structures. We present a system which can estimate the accurate poses of multiple known objects in contact and occlusion from real-time, embodied multi-view vision. Our approach makes 3D object pose proposals from single RGBD views, accumulates pose estimates and non-parametric occupancy information from multiple views as the camera moves, and performs joint optimization to estimate consistent, non-intersecting poses for multiple objects in contact. We verify the accuracy and robustness of our approach experimentally on 2 object datasets: YCB-Video, and our own challenging Cluttered YCB-Video. We demonstrate a real-time robotics application where a robot arm precisely and orderly disassembles complicated piles of objects, using only on-board RGB-D vision  

